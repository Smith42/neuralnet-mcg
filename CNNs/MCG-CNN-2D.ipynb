{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.learn.python.learn as learn\n",
    "import tflearn \n",
    "import scipy as sp\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle, randint\n",
    "import pandas as pd\n",
    "import six\n",
    "from sklearn.utils import shuffle as mutualShuf\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_curve\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 3 # How many folds in the k-fold x-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def importPickle(fileLocation): # File location is ./inData/6060DataFrame.pkl\n",
    "    \"\"\"\n",
    "    Imports Daniel Wilson's datafile and respectively returns a matrix of class \n",
    "    (whether patient is healthy or unhealthy) data, and a matrix of coil data.\n",
    "    \"\"\"\n",
    "    # Import dataframe\n",
    "    path60  = fileLocation\n",
    "    df60 = pd.read_pickle(path60)\n",
    "    # Separate pandas dataframe into classification and data arrays\n",
    "    classData = df60[\"Classification\"].as_matrix()\n",
    "    coilData = df60[\"Coil Data\"].as_matrix()\n",
    "    \n",
    "    return classData, coilData\n",
    "\n",
    "def splitData(coilData, classData):\n",
    "    \"\"\"\n",
    "    Split data into healthy and ill types.\n",
    "    \"\"\"\n",
    "    illData = []\n",
    "    healthData = []\n",
    "    \n",
    "    for index, item in enumerate(classData):\n",
    "        if item == 1:\n",
    "            illData.append(coilData[index])\n",
    "        if item == 0:\n",
    "            healthData.append(coilData[index])\n",
    "            \n",
    "    return illData, healthData\n",
    "\n",
    "classData, coilData = importPickle(\"./inData/6060DataFrame.pkl\")\n",
    "# Normalise coilData\n",
    "for index, item in enumerate(coilData):\n",
    "    coilData[index] = normalize(item, axis=1)\n",
    "\n",
    "illData, healthData = splitData(coilData, classData)\n",
    "if k == 1:\n",
    "    illUnseen = np.array(illData[:20])\n",
    "    healthUnseen = np.array(healthData[:20])\n",
    "    illData = np.array(illData[20:])\n",
    "    healthData = np.array(healthData[20:])\n",
    "    print(illData.shape, healthData.shape,\"\\n\", illUnseen.shape, healthUnseen.shape)\n",
    "else:\n",
    "    illData = np.array(illData)\n",
    "    healthData = np.array(healthData)\n",
    "    print(illData.shape, healthData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def processClassData(classData):\n",
    "    \"\"\"\n",
    "    Process classData.\n",
    "    \n",
    "    Returns a one-hot array of shape [len(classData), 2].\n",
    "    \"\"\"\n",
    "    # Convert label data to one-hot array\n",
    "          \n",
    "    classDataOH = np.zeros((len(classData),2))\n",
    "    classDataOH[np.arange(len(classData)), classData] = 1\n",
    "    \n",
    "    return classDataOH\n",
    "\n",
    "def visualiseData(ecgData, classData, gridSize, axis):\n",
    "    \"\"\"\n",
    "    Plot labelled example data in a gridSize*gridSize grid.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(gridSize, gridSize)\n",
    "    plt.suptitle(\"Labelled example data\")\n",
    "    r = randint(0,len(classData)-16)\n",
    "    k = 0\n",
    "    for i in np.arange(0,gridSize,1):\n",
    "        for j in np.arange(0,gridSize,1):\n",
    "            k = k + 1\n",
    "            ax[i,j].imshow(ecgData[r+k, :, ::40], cmap='gray', interpolation='nearest')\n",
    "            if axis == False:\n",
    "                ax[i,j].axis(\"off\")\n",
    "            ax[i,j].annotate(classData[r+k], xy=(0, 0), xycoords='axes points',\\\n",
    "                        size=10, ha='left', va='top')\n",
    "\n",
    "def functionTown(illArr, healthArr, shuffle):\n",
    "    \"\"\"\n",
    "    Return the processed ecgData and the classData (one-hot). Also return arrays of ill and healthy ppts.\n",
    "    If shuffle is true, shuffle data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ill samples\", len(illArr))\n",
    "    print(\"healthy samples\", len(healthArr))\n",
    "    \n",
    "    classData = []\n",
    "    for i in np.arange(0, len(illArr), 1):\n",
    "        classData.append(1)\n",
    "    for i in np.arange(0, len(healthArr), 1):\n",
    "        classData.append(0)\n",
    "    ecgData = np.reshape(np.append(illArr, healthArr), (-1, 15, 2000))\n",
    "    \n",
    "    if shuffle == True:\n",
    "        classData, ecgData = mutualShuf(np.array(classData), ecgData, random_state=0)\n",
    "        \n",
    "    classDataOH = processClassData(classData)\n",
    "    return np.array(ecgData), classDataOH, classData\n",
    "    \n",
    "ecgData, classDataOH, classData = functionTown(illData, healthData, True)\n",
    "# Reintegrate the found values...\n",
    "print(ecgData.shape)\n",
    "#ecgData = np.cumsum(ecgData, axis=2)\n",
    "ecgData = np.reshape(ecgData, (-1,15,2000,1))\n",
    "# Split ecgData into k sets so we can perform k-fold cross validation:\n",
    "kfoldData = np.array_split(ecgData, k)\n",
    "kfoldLabelsOH = np.array_split(classDataOH, k)\n",
    "kfoldLabels = np.array_split(classData, k)\n",
    "\n",
    "# Get the unseen data:\n",
    "if k == 1:\n",
    "    unseenData, unseenClassOH, unseenClass = functionTown(illUnseen, healthUnseen, True)\n",
    "    #unseenData =  np.cumsum(unseenData, axis=2)\n",
    "    unseenData = np.reshape(unseenData, (-1,15,2000,1))\n",
    "    iUnseen, hUnseen = splitData(unseenData, unseenClass)\n",
    "    unseenHL = np.tile([1,0], (len(hUnseen), 1))\n",
    "    unseenIL = np.tile([0,1], (len(iUnseen), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ecgData.shape)\n",
    "visualiseData(np.reshape(ecgData, (-1,15,2000)), classData, 2, False)\n",
    "plt.savefig(\"../thesis/images/mcg2d.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(ecgData.shape)\n",
    "plt.imshow(np.reshape(ecgData, (-1,15,2000))[20,:,::40], cmap=\"hot\")\n",
    "plt.ylabel(\"Coil number\")\n",
    "plt.xlabel(\"Time axis (subsampled [::40])\")\n",
    "plt.title(\"Example MCG output over all coils\")\n",
    "plt.savefig(\"/tmp/11.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.reshape(ecgData, (-1,15,2000))[20,7,::20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if k == 1:\n",
    "    visualiseData(np.reshape(unseenData, (-1,15,2000)), unseenClass, 2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"/tmp/kData\", kfoldData)\n",
    "np.save(\"/tmp/klabels\", kfoldLabels)\n",
    "np.save(\"/tmp/klabelsOH\", kfoldLabelsOH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "healthEval = []\n",
    "illEval = []\n",
    "spec = []\n",
    "sens = []\n",
    "unseenSpec = []\n",
    "unseenSens = []\n",
    "unseenAvg = []\n",
    "roc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if k != 1: # Perform a k fold cross validation\n",
    "    for i in np.arange(0,k,1):\n",
    "        sess = tf.InteractiveSession()\n",
    "        tf.reset_default_graph()\n",
    "        tflearn.initializations.normal()\n",
    "\n",
    "        # Input layer:\n",
    "        net = tflearn.layers.core.input_data(shape=[None, 15, 2000, 1])\n",
    "\n",
    "        # First layer:\n",
    "        net = tflearn.layers.conv.conv_2d(net, 32, [15,5], activation=\"leaky_relu\")\n",
    "        net = tflearn.layers.conv.max_pool_2d(net, 2, strides=2)\n",
    "        \n",
    "        # Second layer (added)\n",
    "        net = tflearn.layers.conv.conv_2d(net, 64, [15,5], activation=\"leaky_relu\")\n",
    "        net = tflearn.layers.conv.max_pool_2d(net, 2, strides=2)\n",
    "\n",
    "        # Fully connected layer 1:\n",
    "        net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "\n",
    "        # Dropout layer:\n",
    "        net = tflearn.layers.core.dropout(net, keep_prob=0.5)\n",
    "\n",
    "        # Output layer:\n",
    "        net = tflearn.layers.core.fully_connected(net, 2, activation=\"softmax\")\n",
    "\n",
    "        net = tflearn.layers.estimator.regression(net, optimizer='adam', loss='categorical_crossentropy',\\\n",
    "                                 learning_rate=0.0001)\n",
    "\n",
    "        model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "        dummyData = np.reshape(np.concatenate(kfoldData[:i] + kfoldData[i+1:], axis=0), [-1, 15, 2000, 1])\n",
    "        dummyLabels = np.reshape(np.concatenate(kfoldLabelsOH[:i] + kfoldLabelsOH[i+1:], axis=0), [-1, 2])\n",
    "        model.fit(dummyData[:,:,:], dummyLabels, n_epoch=30, show_metric=True)\n",
    "\n",
    "        illTest = []\n",
    "        healthTest = []\n",
    "        for index, item in enumerate(kfoldLabels[i]):\n",
    "            if item == 1:\n",
    "                illTest.append(kfoldData[i][index])\n",
    "            if item == 0:\n",
    "                healthTest.append(kfoldData[i][index])\n",
    "\n",
    "        healthLabel = np.tile([1,0], (len(healthTest), 1))\n",
    "        illLabel = np.tile([0,1], (len(illTest), 1))\n",
    "\n",
    "        sens.append(model.evaluate(np.array(healthTest), healthLabel))\n",
    "        spec.append(model.evaluate(np.array(illTest), illLabel))\n",
    "        \n",
    "        # Get roc curve data\n",
    "        predicted = np.array(model.predict(np.array(kfoldData[i])))\n",
    "        fpr, tpr, th = roc_curve(kfoldLabels[i], predicted[:,1])\n",
    "        roc.append([fpr, tpr])\n",
    "\n",
    "if k == 1: # Only do one run\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.reset_default_graph()\n",
    "    tflearn.initializations.normal()\n",
    "\n",
    "    # Input layer:\n",
    "    net = tflearn.layers.core.input_data(shape=[None, 15, 500, 1])\n",
    "\n",
    "    # First layer:\n",
    "    net = tflearn.layers.conv.conv_2d(net, 32, [15,3],  activation=\"leaky_relu\")\n",
    "    net1 = net\n",
    "    net = tflearn.layers.conv.max_pool_2d(net, 2)\n",
    "\n",
    "    # Second layer:\n",
    "    net = tflearn.layers.conv.conv_2d(net, 64, [15,3], activation=\"leaky_relu\")\n",
    "    net3 = net\n",
    "    net = tflearn.layers.conv.max_pool_2d(net, 2)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "\n",
    "    # Dropout layer:\n",
    "    net = tflearn.layers.core.dropout(net, keep_prob=0.5)\n",
    "\n",
    "    # Output layer:\n",
    "    net = tflearn.layers.core.fully_connected(net, 2, activation=\"softmax\")\n",
    "    \n",
    "    net = tflearn.layers.estimator.regression(net, optimizer='adam', learning_rate=0.0001, loss='categorical_crossentropy')\n",
    "\n",
    "    model = tflearn.DNN(net, tensorboard_verbose=3)\n",
    "    model.fit(ecgData[:,:,::4], classDataOH, batch_size=32, n_epoch=10, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if k != 1:\n",
    "    print(\"Specificity:\", spec, \"\\nAvg:\", np.mean(spec), \"\\nSensitivity:\", sens, \"\\nAvg:\", np.mean(sens))\n",
    "\n",
    "else:\n",
    "    print(model.evaluate(unseenData[:,:,::4], unseenClassOH),\"\\n\",\\\n",
    "    model.evaluate(np.array(iUnseen)[:,:,::4], unseenIL),\"\\n\",\\\n",
    "    model.evaluate(np.array(hUnseen)[:,:,::4], unseenHL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ROC curves\n",
    "if k == 1:\n",
    "    predicted = np.array(model.predict(np.array(unseenData)[:,:,::4]))\n",
    "    fpr, tpr, th = roc_curve(unseenClass, predicted[:,1])\n",
    "    plt.plot(fpr,tpr)\n",
    "    \n",
    "if k != 1:\n",
    "    for i in np.arange(k):\n",
    "        plt.plot(roc[i][0], roc[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do the filters look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_convolutions(model, layer, padding=4, filename=''):\n",
    "    \"\"\"\n",
    "    Taken from smistad @ https://github.com/tflearn/tflearn/issues/291.\n",
    "    \"\"\"\n",
    "    if isinstance(layer, six.string_types):\n",
    "        vars = tflearn.get_layer_variables_by_name(layer)\n",
    "        variable = vars[0]\n",
    "    else:\n",
    "        variable = layer.W\n",
    "\n",
    "    data = model.get_weights(variable)\n",
    "\n",
    "    # N is the total number of convolutions\n",
    "    N = data.shape[2] * data.shape[3]\n",
    "    print(data.shape)\n",
    "\n",
    "    # Ensure the resulting image is square\n",
    "    filters_per_row = int(np.ceil(np.sqrt(N)))\n",
    "    # Assume the filters are square\n",
    "    filter_size = data.shape[0], data.shape[1]\n",
    "    # Size of the result image including padding\n",
    "    result_size = filters_per_row * (filter_size[0] + padding) - padding, \\\n",
    "                    filters_per_row * (filter_size[1] + padding) - padding\n",
    "    # Initialize result image to all zeros\n",
    "    result = np.zeros((result_size[0], result_size[1]))\n",
    "\n",
    "    # Tile the filters into the result image\n",
    "    filter_x = 0\n",
    "    filter_y = 0\n",
    "    for n in range(data.shape[3]):\n",
    "        for c in range(data.shape[2]):\n",
    "            if filter_x == filters_per_row:\n",
    "                filter_y += 1\n",
    "                filter_x = 0\n",
    "            for i in range(filter_size[0]):\n",
    "                for j in range(filter_size[1]):\n",
    "                    result[filter_y * (filter_size[0] + padding) + i, filter_x * (filter_size[1] + padding) + j] = \\\n",
    "                        data[i, j, c, n]\n",
    "            filter_x += 1\n",
    "\n",
    "    # Normalize image to 0-1\n",
    "    min = result.min()\n",
    "    max = result.max()\n",
    "    result = (result - min) / (max - min)\n",
    "\n",
    "    # Plot figure\n",
    "    plt.figure(figsize=(10, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(result.T, cmap='hot', interpolation='nearest')\n",
    "\n",
    "    # Save plot if filename is set\n",
    "    if filename != '':\n",
    "        plt.savefig(filename, bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, net1, padding=4, filename='filters_2dConv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_convolutions(model, net3, padding=2, filename='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
