{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.learn.python.learn as learn\n",
    "import tflearn \n",
    "import scipy as sp\n",
    "from scipy.signal import find_peaks_cwt as peakFinder\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle, randint\n",
    "import pandas as pd\n",
    "import six\n",
    "from sklearn.utils import shuffle as mutualShuf\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def importPickle(fileLocation): # File location is ./inData/6060DataFrame.pkl\n",
    "    \"\"\"\n",
    "    Imports Daniel Wilson's datafile and respectively returns a matrix of class \n",
    "    (whether patient is healthy or unhealthy) data, and a matrix of coil data.\n",
    "    \"\"\"\n",
    "    # Import dataframe\n",
    "    path60  = fileLocation\n",
    "    df60 = pd.read_pickle(path60)\n",
    "    # Separate pandas dataframe into classification and data arrays\n",
    "    classData = df60[\"Classification\"].as_matrix()\n",
    "    coilData = df60[\"Coil Data\"].as_matrix()\n",
    "    \n",
    "    return classData, coilData\n",
    "\n",
    "def splitData(coilData, classData):\n",
    "    \"\"\"\n",
    "    Split data into healthy and ill types.\n",
    "    \"\"\"\n",
    "    illData = []\n",
    "    healthData = []\n",
    "    \n",
    "    for index, item in enumerate(classData):\n",
    "        if item == 1:\n",
    "            illData.append(coilData[index])\n",
    "        if item == 0:\n",
    "            healthData.append(coilData[index])\n",
    "            \n",
    "    return illData, healthData\n",
    "\n",
    "classData, coilData = importPickle(\"./inData/6060DataFrame.pkl\")\n",
    "# Normalise the data\n",
    "for index, item in enumerate(coilData):\n",
    "    coilData[index] = normalize(item, axis=1)\n",
    "\n",
    "illData, healthData = splitData(coilData, classData)\n",
    "\n",
    "if k == 1:\n",
    "    illUnseen = np.vstack(np.array(illData[:20]))#[:,::40]\n",
    "    healthUnseen = np.vstack(np.array(healthData[:20]))#[:,::40]\n",
    "    illData = np.vstack(np.array(illData[20:]))#[:,::40]\n",
    "    healthData = np.vstack(np.array(healthData[20:]))#[:,::40]\n",
    "    print(illData.shape, healthData.shape,\"\\n\", illUnseen.shape, healthUnseen.shape)\n",
    "    \n",
    "if k != 1:\n",
    "    illData = np.array_split(illData, k)\n",
    "    healthData = np.array_split(healthData, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various plots...\n",
    "r = randint(0,390)\n",
    "print(r)\n",
    "fig, ax = plt.subplots(3,3)\n",
    "for i in np.arange(0,ax.shape[0],1):\n",
    "    for j in np.arange(0,ax.shape[1],1):\n",
    "        r = r+1\n",
    "        for l in np.arange(0,15):\n",
    "            ax[i,j].plot(coilData[r][l, 0:2000])\n",
    "            ax[i,j].set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processClassData(classData):\n",
    "    \"\"\"\n",
    "    Process classData.\n",
    "    \n",
    "    Returns a one-hot array of shape [len(classData), 2].\n",
    "    \"\"\"\n",
    "    # Convert label data to one-hot array\n",
    "          \n",
    "    classDataOH = np.zeros((len(classData),2))\n",
    "    classDataOH[np.arange(len(classData)), classData] = 1\n",
    "    \n",
    "    return classDataOH\n",
    "\n",
    "def visualiseData(ecgData, classData, gridSize, axis):\n",
    "    \"\"\"\n",
    "    Plot labelled example data in a gridSize*gridSize grid.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(gridSize, gridSize)\n",
    "    plt.suptitle(\"Labelled example data\")\n",
    "    r = randint(0,len(classData)-16)\n",
    "    l = 0\n",
    "    for i in np.arange(0,gridSize,1):\n",
    "        for j in np.arange(0,gridSize,1):\n",
    "            l = l + 1\n",
    "            ax[i,j].plot(ecgData[r+l])\n",
    "            if axis == False:\n",
    "                ax[i,j].axis(\"off\")\n",
    "            ax[i,j].annotate(classData[r+l], xy=(0, 0), xycoords='axes points',\\\n",
    "                        size=10, ha='left', va='top')\n",
    "\n",
    "def functionTown(illArr, healthArr, shuffle):\n",
    "    \"\"\"\n",
    "    Return the processed ecgData and the classData (one-hot). Also return arrays of ill and healthy ppts.\n",
    "    If shuffle is true, shuffle data.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ill samples\", len(illArr))\n",
    "    print(\"healthy samples\", len(healthArr))\n",
    "    \n",
    "    classData = []\n",
    "    for i in np.arange(0, len(illArr)*15, 1):\n",
    "        classData.append(1)\n",
    "    for i in np.arange(0, len(healthArr)*15, 1):\n",
    "        classData.append(0)\n",
    "    ecgData = np.reshape(np.append(illArr, healthArr), (-1,2000))\n",
    "    print(ecgData.shape)\n",
    "    \n",
    "    if shuffle == True:\n",
    "        classData, ecgData = mutualShuf(np.array(classData), ecgData, random_state=0)\n",
    "        \n",
    "    classDataOH = processClassData(classData)\n",
    "    ecgData = np.reshape(ecgData, (-1,2000,1))\n",
    "    return ecgData, classDataOH, classData\n",
    "\n",
    "if k == 1:\n",
    "    ecgData, classDataOH, classData = functionTown(illData, healthData, True)\n",
    "    # Reintegrate the found values...\n",
    "    #ecgData = np.cumsum(ecgData, axis=1)\n",
    "\n",
    "    # Get the unseen data:\n",
    "    unseenData, unseenClassOH, unseenClass = functionTown(illUnseen, healthUnseen, True)\n",
    "    #unseenData =  np.cumsum(unseenData, axis=1)\n",
    "    iUnseen, hUnseen = splitData(unseenData, unseenClass)\n",
    "    unseenHL = np.tile([1,0], (len(hUnseen), 1))\n",
    "    unseenIL = np.tile([0,1], (len(iUnseen), 1))\n",
    "\n",
    "kfoldData = []\n",
    "kfoldLabels = []\n",
    "kfoldLabelsOH = []\n",
    "    \n",
    "if k != 1:\n",
    "    kfoldStuff = []\n",
    "    for i in np.arange(0,k,1):\n",
    "        kfoldStuff.append(functionTown(illData[i], healthData[i], True))\n",
    "        kfoldData.append(kfoldStuff[i][0])\n",
    "        kfoldLabelsOH.append(kfoldStuff[i][1])\n",
    "        kfoldLabels.append(kfoldStuff[i][2])\n",
    "        print(len(kfoldData), len(kfoldLabels), len(kfoldLabelsOH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualiseData(kfoldData[0], kfoldLabels[0], 2, False)\n",
    "#plt.savefig(\"../thesis/images/mcg1D.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,1000,0.5), kfoldData[0][4])\n",
    "plt.title(\"Example MCG output from single SQUID\")\n",
    "plt.xlabel(\"Time (ms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if k == 1:\n",
    "    healthEval = []\n",
    "    illEval = []\n",
    "    unseenSpec = []\n",
    "    unseenSens = []\n",
    "    unseenAvg = []\n",
    "    unseenroc = []\n",
    "    aucu = []\n",
    "    \n",
    "spec = []\n",
    "sens = []\n",
    "roc = []\n",
    "auc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if k != 1:\n",
    "    for i in np.arange(0,k,1):\n",
    "        sess = tf.InteractiveSession()\n",
    "        tf.reset_default_graph()\n",
    "        tflearn.initializations.normal()\n",
    "\n",
    "        # Input layer:\n",
    "        net = tflearn.layers.core.input_data(shape=[None, 2000, 1])\n",
    "\n",
    "        # First layer:\n",
    "        net = tflearn.layers.conv.conv_1d(net, 32, 5, activation=\"leaky_relu\")\n",
    "        net = tflearn.layers.conv.max_pool_1d(net, 2, strides=2)\n",
    "\n",
    "        # Second layer:\n",
    "        net = tflearn.layers.conv.conv_1d(net, 64, 5, activation=\"leaky_relu\")\n",
    "        net = tflearn.layers.conv.max_pool_1d(net, 2, strides=2)\n",
    "        \n",
    "        # Third layer (added)\n",
    "        #net = tflearn.layers.conv.conv_1d(net, 64, 5, activation=\"leaky_relu\")\n",
    "        #net = tflearn.layers.conv.max_pool_1d(net, 2)\n",
    "\n",
    "        # Fully connected layer 1:\n",
    "        net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "        net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "\n",
    "        # Dropout layer:\n",
    "        net = tflearn.layers.core.dropout(net, keep_prob=0.5)\n",
    "\n",
    "        # Output layer:\n",
    "        net = tflearn.layers.core.fully_connected(net, 2, activation=\"softmax\")\n",
    "\n",
    "        net = tflearn.layers.estimator.regression(net, optimizer='adam',\\\n",
    "                                loss='categorical_crossentropy', learning_rate=0.0001)\n",
    "\n",
    "        model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "        dummyData = np.reshape(np.concatenate(kfoldData[:i] + kfoldData[i+1:], axis=0), [-1, 2000, 1])\n",
    "        print(dummyData.shape)\n",
    "        dummyLabels = np.reshape(np.concatenate(kfoldLabelsOH[:i] + \\\n",
    "                                                kfoldLabelsOH[i+1:], axis=0), [-1, 2])\n",
    "        model.fit(dummyData, dummyLabels, n_epoch=25, show_metric=True)\n",
    "\n",
    "        illTest = []\n",
    "        healthTest = []\n",
    "        for index, item in enumerate(kfoldLabels[i]):\n",
    "            if item == 1:\n",
    "                illTest.append(kfoldData[i][index])\n",
    "            if item == 0:\n",
    "                healthTest.append(kfoldData[i][index])\n",
    "\n",
    "        healthLabel = np.tile([1,0], (len(healthTest), 1))\n",
    "        illLabel = np.tile([0,1], (len(illTest), 1))\n",
    "\n",
    "        sens.append(model.evaluate(np.array(healthTest), healthLabel))\n",
    "        spec.append(model.evaluate(np.array(illTest), illLabel))\n",
    "        \n",
    "        predicted = np.array(model.predict(np.array(kfoldData[i])))\n",
    "        \n",
    "        fpr, tpr, th = roc_curve(kfoldLabels[i], predicted[:,1])\n",
    "        roc.append((fpr,tpr))\n",
    "        auc.append(roc_auc_score(kfoldLabels[i], predicted[:,1]))\n",
    "    \n",
    "if k == 1:\n",
    "    sess = tf.InteractiveSession()\n",
    "    tf.reset_default_graph()\n",
    "    tflearn.initializations.normal()\n",
    "\n",
    "    # Input layer:\n",
    "    net0 = tflearn.layers.core.input_data(shape=[None, 2000, 1])\n",
    "\n",
    "    # First layer:\n",
    "    net1 = tflearn.layers.conv.conv_1d(net0, 32, 10, activation=\"leaky_relu\")\n",
    "    net2 = tflearn.layers.conv.max_pool_1d(net1, 2)\n",
    "\n",
    "    # Second layer:\n",
    "    net3 = tflearn.layers.conv.conv_1d(net2, 64, 5, activation=\"leaky_relu\")\n",
    "    net4 = tflearn.layers.conv.max_pool_1d(net3, 2)\n",
    "\n",
    "    # Fully connected layer 1:\n",
    "    net5 = tflearn.layers.core.fully_connected(net4, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "\n",
    "    # Dropout layer:\n",
    "    net6 = tflearn.layers.core.dropout(net5, keep_prob=0.5)\n",
    "\n",
    "    # Output layer:\n",
    "    net7 = tflearn.layers.core.fully_connected(net6, 2, activation=\"softmax\")\n",
    "\n",
    "    net8 = tflearn.layers.estimator.regression(net7, optimizer='adam', loss='categorical_crossentropy',\\\n",
    "                             learning_rate=0.0001)\n",
    "\n",
    "    model = tflearn.DNN(net0, tensorboard_verbose=3)\n",
    "    model.fit(ecgData, classDataOH, n_epoch=5, validation_set=0.1, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if k != 1:\n",
    "    print(\"Specificity:\", spec, \"\\nAvg:\", np.mean(spec), np.std(spec)/np.sqrt(k), \\\n",
    "          \"\\nSensitivity:\", sens, \"\\nAvg:\", np.mean(sens), np.std(sens)/np.sqrt(k), \\\n",
    "         \"\\nAUC\", auc, \"\\nAvg:\", np.mean(auc), np.std(auc)/np.sqrt(k))\n",
    "\n",
    "if k == 1:\n",
    "    print(model.evaluate(unseenData, unseenClassOH),\"\\n\",\\\n",
    "    model.evaluate(np.array(iUnseen), unseenIL),\"\\n\",\\\n",
    "    model.evaluate(np.array(hUnseen), unseenHL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"./outData/finalData/1d_results_10k_25epoch\", (spec, sens, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "if k != 1:\n",
    "    for i in np.arange(k):\n",
    "        plt.plot(roc[i][0], roc[i][1], \"--\")\n",
    "        #plt.plot(unseenroc[i][0], unseenroc[i][1])\n",
    "        \n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC curves for 1D MCG CNN after 25 epochs\")\n",
    "#plt.savefig(\"../thesis/images/roc_mcg1d.pdf\")\n",
    "\n",
    "np.save(\"./outData/finalData/1d25epoch10k.npy\", roc)\n",
    "print(auc)\n",
    "if k == 1:\n",
    "    fpr, tpr, th = roc_curve(kfoldLabels[i], predicted[:,1])\n",
    "    plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netTst = tf.reshape(tf.tile(tf.reshape(net1, [-1]), [15]), [-1, 2000, 15, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do the filters look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w1 = net1.W\n",
    "weights1 = model.get_weights(w1)\n",
    "expandedWeights1 = np.reshape(np.tile(np.reshape(weights1, [10,32]), [15]), [10,15,1,32])\n",
    "plt.imshow(np.transpose(expandedWeights1[:,:,0,2]), cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weights[:,:,0,2].T, cmap='gray', interpolation='nearest')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = net1.b\n",
    "biases1 = model.get_weights(var2)\n",
    "b2 = net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = net3.W\n",
    "data1 = model.get_weights(var2)\n",
    "print(data1[:,0,0,0])\n",
    "plt.imshow(data1[:,0,0], cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
