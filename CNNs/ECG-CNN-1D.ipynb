{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ipynb for a 1-D CNN for classifying ECGs\n",
    "Best results found so far used:\n",
    "    * 3 VCG leads concatenated\n",
    "    * 200 buffer, 150 shift (looking at QRS -> T lump)\n",
    "    * Input data chunked into 10000 healthy and 10000 unhealthy samples\n",
    "    * Peak finder threshold of 0.02 on differentiated and absoluted input data \n",
    "    (then it is returned to undiff, unabs data before it is fed in)\n",
    "    * Trained over 1 epoch.\n",
    "    * The CNN:\n",
    "        * Conv with 32 features, map 5 wide.\n",
    "        * 2 wide max pool.\n",
    "        * Conv 64 features, map 5 wide.\n",
    "        * 2 wide max pool.\n",
    "        * 1024 neuron dense layer, L2 regularisation with weight_decay=0.001.\n",
    "        * 50% dropout layer.\n",
    "        * 2 wide softmax layer.\n",
    "        * ADAM optimiser with learning_rate=0.00001.\n",
    "        * Loss function is categorical x-entropy.\n",
    "        \n",
    "This gives a result of Sensitivity: 1.0 Specifity: 0.9965 Accuracy: 0.9982 for data taken from the training set (but not trained with).\n",
    "And Sensitivity: 0.9988 Specifity: 0.9959 Accuracy: 0.9974 on patients it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow.contrib.learn.python.learn as learn\n",
    "import tflearn \n",
    "import scipy as sp\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle, randint\n",
    "from sklearn.utils import shuffle as mutualShuf\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def importData(filepath):\n",
    "    ppt = np.genfromtxt(filepath)\n",
    "    dppt = np.diff(np.transpose(ppt)) \n",
    "    print(filepath, \"Shape:\", dppt[1:16,:].shape)\n",
    "    return dppt[1:16,:]\n",
    "\n",
    "pathIll = \"./inData/clean_ecg/ill/\"\n",
    "pathHealth = \"./inData/clean_ecg/health/\"\n",
    "illLst = []\n",
    "healthLst = []\n",
    "\n",
    "for file in os.listdir(pathIll):\n",
    "    illLst.append(importData(pathIll+file))\n",
    "for file in os.listdir(pathHealth):\n",
    "    healthLst.append(importData(pathHealth+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If 0 <= lead < 15, then output that lead number. If lead = 15 output a cat array of standard ECG leads.\n",
    "# If lead == 16 only output Frank leads vx, vy, vz. If lead is anything else output whole dataset flattened.\n",
    "# If lead == 17 output all leads in a cat array.\n",
    "lead = 16\n",
    "\n",
    "if 0 <= lead < 15:\n",
    "    print(\"Selecting lead\", lead)\n",
    "    healthPat = np.concatenate((healthLst), axis=1)[lead]\n",
    "    illPat = np.concatenate((illLst), axis=1)[lead]\n",
    "    healthPat = np.reshape(healthPat, (1,-1))\n",
    "    illPat = np.reshape(illPat, (1,-1))\n",
    "\n",
    "elif lead == 15:\n",
    "    print(\"Outputting standard ECG leads\")\n",
    "    healthPat = np.concatenate((healthLst[:]), axis=1)[0:12]\n",
    "    illPat = np.concatenate((illLst[:]), axis=1)[0:12]\n",
    "\n",
    "elif lead == 16:\n",
    "    print(\"Outputing Frank leads\")\n",
    "    healthPat = np.concatenate((healthLst[:]), axis=1)[12:15]\n",
    "    illPat = np.concatenate((illLst[:]), axis=1)[12:15]\n",
    "    \n",
    "elif lead == 17:\n",
    "    print(\"Outputing all leads\")\n",
    "    healthPat = np.concatenate((healthLst[:]), axis=1)\n",
    "    illPat = np.concatenate((illLst[:]), axis=1)\n",
    "    \n",
    "else:\n",
    "    print(\"Lead says\", lead, \"so selecting whole thing\")\n",
    "    healthPat = np.hstack(np.concatenate((healthLst[:]), axis=1))\n",
    "    illPat = np.hstack(np.concatenate((healthLst[:]), axis=1))\n",
    "    healthPat = np.reshape(healthPat, (1,-1))\n",
    "    illPat = np.reshape(illPat, (1,-1))\n",
    "    \n",
    "print(healthPat.shape, illPat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAbove(arr, threshold, skip):\n",
    "    \"\"\"\n",
    "    Return indices for values above threshhold in array, arr. Pass over skip amount to reduce \n",
    "    number of similar ECGs.\n",
    "    \"\"\"\n",
    "    inlst = []\n",
    "    for index, item in enumerate(arr):\n",
    "        if item >= threshold:\n",
    "            inlst.append(index)\n",
    "            \n",
    "    return inlst[::skip]\n",
    "\n",
    "def getSamples(Arr, indexArr, buffer, shift):\n",
    "    \"\"\"\n",
    "    Get samples for inputting into CNN. Buffer is \"pixels\" returned either side of peak in indexArr.\n",
    "    Shift is amount the ECG is shifted from the peak centre.\n",
    "    \"\"\"\n",
    "    sampleArr = []\n",
    "    for index, item in enumerate(indexArr):\n",
    "        if Arr[:, item-buffer+shift:item+buffer+shift].shape != (Arr.shape[0], buffer*2):\n",
    "            pass\n",
    "        else:\n",
    "            sampleArr.append(Arr[:, item-buffer+shift:item+buffer+shift])\n",
    "\n",
    "    return np.array(sampleArr)\n",
    "\n",
    "def processClassData(classData):\n",
    "    \"\"\"\n",
    "    Process classData.\n",
    "    \n",
    "    Returns a one-hot array of shape [len(classData), 2].\n",
    "    \"\"\"\n",
    "    # Convert label data to one-hot array\n",
    "          \n",
    "    classDataOH = np.zeros((len(classData),2))\n",
    "    classDataOH[np.arange(len(classData)), classData] = 1\n",
    "    \n",
    "    return classDataOH\n",
    "\n",
    "def visualiseData(ecgData, classData, gridSize, axis):\n",
    "    \"\"\"\n",
    "    Plot labelled example data in a gridSize*gridSize grid.\n",
    "    If Axis is True return plot with labelled axes.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(gridSize, gridSize)\n",
    "    plt.suptitle(\"Labelled example data\")\n",
    "    r = randint(0,len(classData)-16)\n",
    "    k = 0\n",
    "    for i in np.arange(0,gridSize,1):\n",
    "        for j in np.arange(0,gridSize,1):\n",
    "            k = k + 1\n",
    "            ax[i,j].plot(ecgData[r+k])\n",
    "            if axis == False:\n",
    "                ax[i,j].axis(\"off\")\n",
    "            ax[i,j].annotate(classData[r+k], xy=(0, 0), xycoords='axes points',\\\n",
    "                        size=10, ha='left', va='top')\n",
    "\n",
    "def undiff(ecgData, buffer):\n",
    "    \"\"\"\n",
    "    Reverse the differentiation done earlier, through np.cumsum.\n",
    "    \"\"\"\n",
    "    for i in np.arange(0,ecgData.shape[0],1):\n",
    "        for j in np.arange(0,ecgData.shape[1],1):\n",
    "            ecgData[i,j] = np.cumsum(ecgData[i,j])\n",
    "    ecgData = np.reshape(ecgData, (-1, buffer*2, 1))\n",
    "    return ecgData            \n",
    "\n",
    "def chunkify(lst,n):\n",
    "    \"\"\" Chunk a list into n chunks of approximately equal size \"\"\"\n",
    "    return [ lst[i::n] for i in range(n) ]\n",
    "\n",
    "def splitData(coilData, classData):\n",
    "    \"\"\"\n",
    "    Split data into healthy and ill types.\n",
    "    \"\"\"\n",
    "    illData = []\n",
    "    healthData = []\n",
    "    \n",
    "    for index, item in enumerate(classData):\n",
    "        if item == 1:\n",
    "            illData.append(coilData[index])\n",
    "        if item == 0:\n",
    "            healthData.append(coilData[index])\n",
    "            \n",
    "    return illData, healthData\n",
    "\n",
    "def functionTownCat(illArr, healthArr, illThreshold, healthThreshold, skip, shift, buffer, shuffle):\n",
    "    \"\"\"\n",
    "    Return the processed ecgData (each \"heartbeat\") with the leads concatenated into a 2d array,\n",
    "    and the classData (one-hot).\n",
    "    If shuffle is true, shuffle data.\n",
    "    \"\"\"\n",
    "    # Get the samples using my crude peak finder\n",
    "    illPeakArr = findAbove(np.abs(illArr[0]), illThreshold, skip)\n",
    "    sampleArrI = getSamples(illArr, np.array(illPeakArr), buffer, shift)\n",
    "    \n",
    "    healthPeakArr = findAbove(np.abs(healthArr[0]), healthThreshold, skip)\n",
    "    sampleArrH = getSamples(healthArr, np.array(healthPeakArr), buffer, shift)\n",
    "    \n",
    "    # Average over chunks of ~10000 ECG heartbeats\n",
    "    chunkyI = chunkify(sampleArrI, 10000)\n",
    "    chunkyH = chunkify(sampleArrH, 10000)\n",
    "    avgI = []\n",
    "    avgH = []\n",
    "    \n",
    "    for i in np.arange(0,len(chunkyI),1):\n",
    "        avgI.append(np.mean(chunkyI[i], axis=0))\n",
    "        \n",
    "    for i in np.arange(0,len(chunkyH),1):\n",
    "        avgH.append(np.mean(chunkyH[i], axis=0))\n",
    "    \n",
    "    sampleArrI = np.array(avgI)\n",
    "    sampleArrH = np.array(avgH)\n",
    "    \n",
    "    print(\"ill samples\", sampleArrI.shape)\n",
    "    print(\"healthy samples\", sampleArrH.shape)\n",
    "    \n",
    "    # Label the data\n",
    "    classData = []\n",
    "    for i in np.arange(0, sampleArrI.shape[0], 1):\n",
    "        classData.append(1)\n",
    "    for i in np.arange(0, sampleArrH.shape[0], 1):\n",
    "        classData.append(0)\n",
    "    ecgData = np.concatenate((sampleArrI, sampleArrH), axis=0)\n",
    "                        \n",
    "    if shuffle == True:\n",
    "        classData, ecgData = mutualShuf(np.array(classData), ecgData, random_state=0)    \n",
    "    \n",
    "    classDataOH = processClassData(classData)\n",
    "    return ecgData, classDataOH, classData\n",
    "\n",
    "buffer = 200\n",
    "bufferxL = buffer*illPat.shape[0]\n",
    "healthThreshold = 0.02\n",
    "illThreshold = 0.02\n",
    "skip = 1\n",
    "shift = 150\n",
    "shuf = True\n",
    "\n",
    "ecgData, classDataOH, classData = functionTownCat(illPat, healthPat, illThreshold, healthThreshold, skip,\\\n",
    "                                               shift, buffer, shuf)\n",
    "# Reintegrate the found values...\n",
    "ecgData = undiff(ecgData, bufferxL)\n",
    "# Take 20% for testing later:\n",
    "testData = ecgData[:round(ecgData.shape[0]*0.2)]\n",
    "trainData = ecgData[round(ecgData.shape[0]*0.2):]\n",
    "testLabels = classDataOH[:round(ecgData.shape[0]*0.2)]\n",
    "trainLabels = classDataOH[round(ecgData.shape[0]*0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(ecgData.shape)\n",
    "visualiseData(ecgData, classData, 6, False)\n",
    "#plt.savefig(\"./outData/figures/.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ecgData[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.reset_default_graph()\n",
    "tflearn.initializations.normal()\n",
    "\n",
    "# Input layer:\n",
    "net = tflearn.layers.core.input_data(shape=[None, bufferxL*2, 1])\n",
    "\n",
    "# First layer:\n",
    "net = tflearn.layers.conv.conv_1d(net, 32, 5, activation=\"leaky_relu\")\n",
    "net = tflearn.layers.conv.max_pool_1d(net, 2)\n",
    "\n",
    "# Second layer:\n",
    "net = tflearn.layers.conv.conv_1d(net, 64, 5, activation=\"leaky_relu\")\n",
    "net = tflearn.layers.conv.max_pool_1d(net, 2)\n",
    "\n",
    "# Fully connected layer 1:\n",
    "net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "net = tflearn.layers.core.fully_connected(net, 1024, regularizer=\"L2\", weight_decay=0.001, activation=\"leaky_relu\")\n",
    "\n",
    "# Dropout layer:\n",
    "net = tflearn.layers.core.dropout(net, keep_prob=0.5)\n",
    "\n",
    "# Output layer:\n",
    "net = tflearn.layers.core.fully_connected(net, 2, activation=\"softmax\")\n",
    "\n",
    "net = tflearn.layers.estimator.regression(net, optimizer='adam', loss='categorical_crossentropy',\\\n",
    "                         learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(trainData, trainLabels, n_epoch=1, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model?\n",
    "#now = datetime.datetime.now()\n",
    "#model.save(\"./outData/models/cleanECG_undiff_FrankCAT2_\"+now.isoformat()+\"_.tflearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test accuracy of model(s)\n",
    "## 20% of training data set aside for testing (4000 \"heartbeats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labellst = classData[:round(ecgData.shape[0]*0.2)]\n",
    "healthTest = []\n",
    "illTest = []\n",
    "for index, item in enumerate(labellst):\n",
    "    if item == 1:\n",
    "        illTest.append(testData[index])\n",
    "    if item == 0:\n",
    "        healthTest.append(testData[index])\n",
    "\n",
    "healthLabel = np.tile([1,0], (len(healthTest), 1))\n",
    "illLabel = np.tile([0,1], (len(illTest), 1))\n",
    "\n",
    "predicted = np.array(model.predict(testData))\n",
    "                      \n",
    "print(\"Sensitivity:\", model.evaluate(np.array(healthTest), healthLabel), \"Specifity:\",\\\n",
    "    model.evaluate(np.array(illTest), illLabel),\\\n",
    "    \"Accuracy:\", model.evaluate(testData, testLabels),\\\n",
    "     \"AUC:\", roc_auc_score(labellst, predicted[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if the model hasn't seen data from the patient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpathIll = \"./inData/clean_ecg/testIll/\"\n",
    "tpathHealth = \"./inData/clean_ecg/testHealth/\"\n",
    "tillLst = []\n",
    "thealthLst = []\n",
    "\n",
    "for file in os.listdir(tpathIll):\n",
    "    tillLst.append(importData(tpathIll+file))\n",
    "for file in os.listdir(tpathHealth):\n",
    "    thealthLst.append(importData(tpathHealth+file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0 <= lead < 15:\n",
    "    print(\"Selecting lead\", lead)\n",
    "    thealth = np.concatenate((thealthLst), axis=1)[lead]\n",
    "    till = np.concatenate((tillLst), axis=1)[lead]\n",
    "    thealth = np.reshape(thealth, (1,-1))\n",
    "    till = np.reshape(till, (1,-1))\n",
    "\n",
    "elif lead == 15:\n",
    "    print(\"Outputting array of standard ECG leads\")\n",
    "    thealth = np.concatenate((thealthLst[:]), axis=1)[0:12]\n",
    "    till = np.concatenate((tillLst[:]), axis=1)[0:12]\n",
    "    \n",
    "elif lead == 16:\n",
    "    print(\"Outputing Frank leads\")\n",
    "    thealth = np.concatenate((thealthLst[:]), axis=1)[12:15]\n",
    "    till = np.concatenate((tillLst[:]), axis=1)[12:15]       \n",
    "    \n",
    "elif lead == 17:\n",
    "    print(\"Outputing all leads\")\n",
    "    thealth = np.concatenate((thealthLst[:]), axis=1)\n",
    "    till = np.concatenate((tillLst[:]), axis=1)    \n",
    "    \n",
    "else:\n",
    "    print(\"Lead says\", lead, \"so selecting whole thing\")\n",
    "    thealth = np.hstack(np.concatenate((thealthLst[:]), axis=1))\n",
    "    till = np.hstack(np.concatenate((tillLst[:]), axis=1))\n",
    "    thealth = np.reshape(thealth, (1,-1))\n",
    "    till = np.reshape(till, (1,-1))\n",
    "    \n",
    "print(thealth.shape)                          \n",
    "unseenData, unseenClassOH, unseenClass = functionTownCat(till, thealth, illThreshold, healthThreshold, \\\n",
    "                                                   skip, shift, buffer, True)\n",
    "    \n",
    "# Undifferentiate values\n",
    "unseenData = undiff(unseenData, bufferxL)\n",
    "tillarr, thealtharr = splitData(unseenData, unseenClass)\n",
    "    \n",
    "sens = model.evaluate(np.array(thealtharr), np.tile([1,0], (len(thealtharr), 1)))[0]\n",
    "spec = model.evaluate(np.array(tillarr), np.tile([0,1], (len(tillarr), 1)))[0]\n",
    "lenh = len(thealtharr)\n",
    "leni = len(tillarr)\n",
    "visualiseData(unseenData, unseenClass, 3, False)    \n",
    "\n",
    "predicted2 = np.array(model.predict(unseenData))\n",
    "\n",
    "print(\"Sensitivity:\", sens,\\\n",
    "      \"Specifity:\", spec,\\\n",
    "      \"Accuracy:\", ((sens*lenh+spec*leni)/(lenh+leni)),\\\n",
    "      \"ROC:\", roc_auc_score(unseenClass, predicted2[:,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
